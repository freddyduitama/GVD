{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0.1.wordcount.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freddyduitama/GVD/blob/master/0_1_wordcount.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eVSCHzjLlZd9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Adecuacion de la plataforma**"
      ]
    },
    {
      "metadata": {
        "id": "k3ZZiSBzPA9u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "alYd_PMvWeMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# instala el ambiente de spark..solo se corre una vez\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yvz9ToTpTgEM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Configura variables de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zz22FmAIYIvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importa package\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjngtzOcT_QR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define  la sesion SPARK. \n",
        "conf = SparkConf().setAppName(\"ejemplo\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGaSqRZYUAjn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Crea la sesión\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SKQSxEV1PHLF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# monta el google drive para usar sus archivos\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H64gn4-aejia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  INST A: Opcional..si quiere subir archivos al ambiente de trabajo desde su PC\n",
        "from google.colab import files\n",
        "datafile = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "usi63kydliJS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Example 1.  Versión básica del word count**"
      ]
    },
    {
      "metadata": {
        "id": "as8HsrKbA8_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OPCION 1  se usa si vas a leer desde tu drive el archivo. En este caso usa la libreria que convierte cada entrada del RDD en un objeto tipo Row= (values=('x x  xx]'))\n",
        "lines=spark.read.text('/gdrive/My Drive/Colab Notebooks/Data/datos.txt').rdd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z62Z5D7KYcoY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OPCION 2usa la libreria basica de SPARk que lee cada entrada del RDD como una cadena de caracteres.\n",
        "lines1 = sc.textFile(\"/gdrive/My Drive/Colab Notebooks/Data/datos.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FK6VHWFFcBSP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OPCIONAL  se usa si cargaste el archivo con INST A.\n",
        "lines=spark.read.text('datos.txt').rdd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxfVS7I1ftjM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Ejecutar si usó OPCION 1\n",
        "import re, string\n",
        "lineLengths = lines.map( lambda s: len(s.value) ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rZ5yDelTZXun",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Ejecutar si usó  OPCION 2\n",
        "lineLengths = lines1.map( lambda s : len(s) ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sgCX0ZegmO7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "totalLength = lineLengths.reduce( lambda a, b : a + b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nMc0oXIgqwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(totalLength); "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-71qER0kVl1Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lineLengths.take(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2AKKr2ealNhq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **EXAMPLE 2: Versión del word count eliminando signos de puntuación y otros caracteres**"
      ]
    },
    {
      "metadata": {
        "id": "w4_hhgtPeT7c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  INST A: para subir el archivo a usar en el word count\n",
        "from google.colab import files\n",
        "datafile = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-pVC6gfugtt9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re, string\n",
        "text_file = spark.read.text(\"/gdrive/My Drive/Colab Notebooks/Data/texto-con-caracteres.txt\").rdd\n",
        "punc = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y8MHoRhjunw7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define función a usar en el map\n",
        "def uni_to_clean_str(x):\n",
        "    lowercased_str = x.lower()\n",
        "    lowercased_str = lowercased_str.replace('--',' ')\n",
        "    clean_str = lowercased_str.translate(punc)\n",
        "    return clean_str"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcGgGEZguvtk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_RDD = text_file.flatMap(lambda x: uni_to_clean_str(x.value).split())\n",
        "one_RDD = one_RDD.map(lambda x: (x,1))\n",
        "one_RDD = one_RDD.reduceByKey(lambda x,y: x + y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d0obLY58YFoy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_RDD.take(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lGCMZUryaUtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lines=spark.read.text('/gdrive/My Drive/Colab Notebooks/Data/texto-con-caracteres.txt').rdd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Go11L9mb5kQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# muesta por qué en el map de debe usar s.value, la estructura de cada entrada del RDD es row(value='xxx')\n",
        "print(lines.take(2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNeCoC2QYUFF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}